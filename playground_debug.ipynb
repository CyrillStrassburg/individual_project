{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import Wind_KAN_\n",
    "import importlib\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Wind_KAN_ import *\n",
    "from kan import *\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "winddata_path = os.path.join('..\\\\Liao_code','Task15_W_Zone6.csv')\n",
    "train_val_split = 0.1\n",
    "train_test_split = 0.1\n",
    "out=False\n",
    "\n",
    "data = pd.read_csv(winddata_path)\n",
    "Y = data.iloc[:, 2].values.astype(np.float64)\n",
    "X = data.iloc[:, 3:7].values.astype(np.float64)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X= scaler.fit_transform(X)\n",
    "split1 = int((1-train_test_split) * train_val_split * len(X))\n",
    "split2 = int((1-train_test_split) * len(X))\n",
    "\n",
    "# for comparison with other models\n",
    "split1 = int(0.7 * len(X))\n",
    "split2 = int(0.85 * len(X))\n",
    "##########################################\n",
    "\n",
    "X_train, y_train = X[:split1], Y[:split1]\n",
    "X_val, y_val = X[split1:split2], Y[split1:split2]\n",
    "X_test, y_test = X[split2:], Y[split2:]\n",
    "\n",
    "ndarray_data = [X_train, y_train, X_val, y_val, X_test, y_test]\n",
    "tensor_data_list = [torch.from_numpy(x) for x in ndarray_data]\n",
    "\n",
    "tensor_data_list[1] = tensor_data_list[1].unsqueeze(1)  # y_train\n",
    "tensor_data_list[3] = tensor_data_list[3].unsqueeze(1)  # y_val\n",
    "tensor_data_list[5] = tensor_data_list[5].unsqueeze(1)  # y_test\n",
    "\n",
    "# The KAN Class trains on train/validation called train_input/test_input\n",
    "# dataset = { 'train_input': tensor_data_list[0].float(),\n",
    "#             'train_label': tensor_data_list[1].float(),\n",
    "#             'test_input': tensor_data_list[2].float(),\n",
    "#             'test_label': tensor_data_list[3].float(),\n",
    "#             'true_test_input': tensor_data_list[4].float(),\n",
    "#             'true_test_label': tensor_data_list[5].float()  }\n",
    "\n",
    "dataset = { 'train_input': tensor_data_list[0],\n",
    "            'train_label': tensor_data_list[1],\n",
    "            'test_input': tensor_data_list[2],\n",
    "            'test_label': tensor_data_list[3],\n",
    "            'true_test_input': tensor_data_list[4],\n",
    "            'true_test_label': tensor_data_list[5]  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan.utils import create_dataset\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# create dataset f(x,y) = exp(sin(pi*x)+y^2)\n",
    "f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "hello_dataset = create_dataset(f, n_var=2, device=device)\n",
    "\n",
    "# for i, key in enumerate(hello_dataset.keys()):\n",
    "#     hello_dataset[key] = hello_dataset[key].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9401, 0.9797])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([0.4335, 0.4534, 0.4360, 0.4929])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(hello_dataset['train_input'][0])\n",
    "print(type(hello_dataset['train_input'][0]))\n",
    "print(dataset['train_input'][0])\n",
    "print(type(dataset['train_input'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "model = KAN(width=[4,1], grid=3, k=3, seed=42, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.97e-01 | test_loss: 1.90e-01 | reg: 4.16e+00 | : 100%|█| 50/50 [00:28<00:00,  1.76it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(dataset, opt=\"LBFGS\", steps=50, lamb=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "hello_model = KAN(width=[2,5,1], grid=3, k=3, seed=42, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.31e-03 | test_loss: 1.32e-03 | reg: 1.80e+01 | : 100%|█| 100/100 [00:45<00:00,  2.20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = hello_model.fit(hello_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.2\n"
     ]
    }
   ],
   "source": [
    "model = model.prune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "wind_model = Wind_KAN(width=[4,1], grid=3, k=3, seed=42, device=device)\n",
    "wind_model.get_winddataset(winddata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def get_winddataset(self, winddata_path, train_val_split = 0.1, train_test_split = 0.1, out=False):\n",
      "        self.winddata_path = winddata_path\n",
      "        data = pd.read_csv(self.winddata_path)\n",
      "        Y = data.iloc[:, 2].values.astype(np.float64)\n",
      "        X = data.iloc[:, 3:7].values.astype(np.float64)\n",
      "\n",
      "        scaler = MinMaxScaler()\n",
      "        X= scaler.fit_transform(X)\n",
      "        split1 = int((1-train_test_split) * train_val_split * len(X))\n",
      "        split2 = int((1-train_test_split) * len(X))\n",
      "\n",
      "        # for comparison with other models\n",
      "        split1 = int(0.7 * len(X))\n",
      "        split2 = int(0.85 * len(X))\n",
      "        ##########################################\n",
      "\n",
      "        X_train, y_train = X[:split1], Y[:split1]\n",
      "        X_val, y_val = X[split1:split2], Y[split1:split2]\n",
      "        X_test, y_test = X[split2:], Y[split2:]\n",
      "\n",
      "        ndarray_data = [X_train, y_train, X_val, y_val, X_test, y_test]\n",
      "        tensor_data_list = [torch.from_numpy(x) for x in ndarray_data]\n",
      "\n",
      "        tensor_data_list[1] = tensor_data_list[1].unsqueeze(1)  # y_train\n",
      "        tensor_data_list[3] = tensor_data_list[3].unsqueeze(1)  # y_val\n",
      "        tensor_data_list[5] = tensor_data_list[5].unsqueeze(1)  # y_test\n",
      "\n",
      "        # The KAN Class trains on train/validation called train_input/test_input\n",
      "        # self.dataset = { 'train_input': tensor_data_list[0].float(),\n",
      "        #             'train_label': tensor_data_list[1].float(),\n",
      "        #             'test_input': tensor_data_list[2].float(),\n",
      "        #             'test_label': tensor_data_list[3].float(),\n",
      "        #             'true_test_input': tensor_data_list[4].float(),\n",
      "        #             'true_test_label': tensor_data_list[5].float()  }\n",
      "\n",
      "        # There may be some kind of inconsistency with .float32 being the explicit datatype\n",
      "        self.dataset = { 'train_input': tensor_data_list[0],\n",
      "                    'train_label': tensor_data_list[1],\n",
      "                    'test_input': tensor_data_list[2],\n",
      "                    'test_label': tensor_data_list[3],\n",
      "                    'true_test_input': tensor_data_list[4],\n",
      "                    'true_test_label': tensor_data_list[5]  }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "lines = inspect.getsource(wind_model.get_winddataset)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.90e-01 | test_loss: 1.88e-01 | reg: 8.57e+00 | : 100%|█| 20/20 [00:07<00:00,  2.52it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = wind_model.fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.89e-01 | test_loss: 1.89e-01 | reg: 8.59e+00 | : 100%|█| 20/20 [00:09<00:00,  2.03it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = wind_model.prune_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
